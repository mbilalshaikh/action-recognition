{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* numpy is the fundamental package for scientific computing with Python.  \n",
    "* h5py is a common package to interact with a dataset that is stored on an H5 file.  \n",
    "* matplotlib is a famous library to plot graphs in Python.  \n",
    "* PIL and scipy are used here to test your model with your own picture at the end.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. training set labbeled with classes\n",
    "2. test set labbeld with classes\n",
    "3. no of training examples\n",
    "4. no of testing examples\n",
    "5. height and width for each data\n",
    "6. size of each image or video or skeleton\n",
    "7. flatten the input\n",
    "8. Standardize/Normalize the data\n",
    "9. initialize model parameters\n",
    "10. learn parameters for the model by minimizing the cost\n",
    "11. use the learned parameters to make predictions (on test set)\n",
    "12. Analyse results and conclude\n",
    "\n",
    "## Steps dor building a neural Network\n",
    "\n",
    "1. Define the model structure ( no of input features )\n",
    "2. Initialize the model parameters\n",
    "3. Loop:  \n",
    "    - Calculate current loss (forward propagation)\n",
    "    - Calculate current gradient (backward propagation)\n",
    "    - Update parameters (gradient descent)\n",
    "    \n",
    "You often build 1-3 separately and integrate them into one function we call `model()`.\n",
    "\n",
    "* with some no of iterations\n",
    "* You get train accuracy \n",
    "* You get test accuracy \n",
    "* plot learning rate through cost values and no of iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear any logs from previous runs\n",
    "!rm -rf ./logs/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train[1][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(tf.keras.Model):\n",
    "  \"\"\"A simple linear model.\"\"\"\n",
    "\n",
    "  def __init__(self):\n",
    "    super(Net, self).__init__()\n",
    "    self.l1 = tf.keras.layers.Dense(5)\n",
    "\n",
    "  def call(self, x):\n",
    "    return self.l1(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_weights('easy_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(net, example, optimizer):\n",
    "  \"\"\"Trains `net` on `example` using `optimizer`.\"\"\"\n",
    "  with tf.GradientTape() as tape:\n",
    "    output = net(example['x'])\n",
    "    loss = tf.reduce_mean(tf.abs(output - example['y']))\n",
    "  variables = net.trainable_variables\n",
    "  gradients = tape.gradient(loss, variables)\n",
    "  optimizer.apply_gradients(zip(gradients, variables))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def toy_dataset():\n",
    "  inputs = tf.range(10.)[:, None]\n",
    "  labels = inputs * 5. + tf.range(5.)[None, :]\n",
    "  return tf.data.Dataset.from_tensor_slices(\n",
    "    dict(x=inputs, y=labels)).repeat().batch(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "earlystop_callback = EarlyStopping(\n",
    "  monitor='val_accuracy', min_delta=0.0001,\n",
    "  patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_checkpoint(net, manager):\n",
    "  ckpt.restore(manager.latest_checkpoint)\n",
    "  if manager.latest_checkpoint:\n",
    "    print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
    "  else:\n",
    "    print(\"Initializing from scratch.\")\n",
    "\n",
    "  for _ in range(50):\n",
    "    example = next(iterator)\n",
    "    loss = train_step(net, example, opt)\n",
    "    ckpt.step.assign_add(1)\n",
    "    if int(ckpt.step) % 10 == 0:\n",
    "      save_path = manager.save()\n",
    "      print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "      print(\"loss {:1.2f}\".format(loss.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(0.1)\n",
    "net = Net()\n",
    "dataset = toy_dataset()\n",
    "iterator = iter(dataset)\n",
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=opt, net=net, iterator=iterator)\n",
    "manager = tf.train.CheckpointManager(ckpt, './tf_ckpts', max_to_keep=3)\n",
    "\n",
    "train_and_checkpoint(net, manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manager.checkpoints)  # List the three remaining checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls ./tf_ckpts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# launch tensorboard\n",
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model(x_train[:1]).numpy()\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.nn.softmax(predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn(y_train[:1], predictions).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=loss_fn,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test,  y_test, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model = tf.keras.Sequential([\n",
    "  model,\n",
    "  tf.keras.layers.Softmax()\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_model(x_test[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
